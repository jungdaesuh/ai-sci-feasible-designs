# StellarForge Quad-Hybrid Integration Guide

**Status**: Ready for Implementation
**Architecture Version**: 2.1 (Quad-Hybrid)
**Date**: 2025-12-10
**Synthesized From**: Opus 4.5, GPT-5.1, Claude Sonnet, Grok, DeepThink analyses

---

## 1. Executive Summary

This document provides **production-ready code** for completing the StellarForge Quad-Hybrid integration. It combines the best insights from five independent AI analyses:

| Source | Key Contribution |
|--------|-----------------|
| **Opus 4.5** | NFP bugs, batched tensor ops, Input/Output type table |
| **GPT-5.1** | Schema normalization for Surrogate compatibility |
| **Claude Sonnet** | Bottleneck analysis (RL is 4Ã— worse than Pre-relax) |
| **Grok** | Drop-in code patterns matching existing workers |
| **DeepThink** | `experiment_setup.py` fix for `diffusion_timesteps` |

**Estimated Implementation Time**: 4-6 hours

---

## 2. Critical Insight: The Real Bottleneck

Claude's timing analysis proves the priority order:

```
Component       Time (1000 seeds)   Priority
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Dreamer         ~2 seconds          âœ… Done
Pre-relaxer     ~50 seconds         ğŸŸ¡ Medium (not blocking)
Geometer        ~1 second           âœ… Done
Surrogate       ~0.5 seconds        âœ… Done
RL Agent        ~200 seconds        ğŸ”´ CRITICAL (refines ALL seeds)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL           ~253.5 seconds
```

> [!IMPORTANT]
> The RL agent currently refines **all 1000+ seeds** instead of just the top-K after surrogate ranking. Fixing this ordering provides **10Ã— speedup** (20s instead of 200s).

---

## 3. Data Flow & Type Conversions (Opus 4.5)

Understanding the data types at each stage prevents integration bugs:

| Component | Input Type | Output Type | Key Conversion |
|-----------|------------|-------------|----------------|
| **Dreamer** | `target_metrics: Dict` | `List[Dict]` with `params: {r_cos, z_sin}` | PCA inverse transform |
| **Pre-relaxer** | `List[Dict]` | `List[Dict]` with smoothed params | Torch tensor â†” nested list |
| **Geometer** | `List[Dict]` | Filtered `List[Dict]` | `torch.tensor(params["r_cos"])` |
| **Surrogate** | `List[Dict]` | `List[SurrogatePrediction]` | `structured_flatten()` |
| **RL Agent** | `List[Dict]` (top-K) | `List[Dict]` with `rl_score` | `structured_unflatten()` + nfp restore |

---

## 4. Critical Bugs Found (Opus 4.5)

### Bug A: NFP Hardcoded in Pre-relaxer

**Location**: [prerelax.py:60-67](file:///Users/suhjungdae/code/software/proxima_fusion/ai-sci-feasible-designs/ai_scientist/optim/prerelax.py#L60-L67)

```python
# CURRENT (WRONG)
def prerelax_boundary(
    boundary_params: Dict[str, Any],
    ...
    nfp: int = 3,  # âŒ Hardcoded to 3!
) -> Tuple[Dict[str, Any], float]:
```

**Impact**: Wrong geometric energy calculation for non-nfp=3 designs.

**Fix**: The `PreRelaxWorker` must extract NFP from `boundary_params` and pass it explicitly:

```python
nfp = int(params.get("n_field_periods", params.get("nfp", 3)))
```

### Bug B: Missing NFP Propagation in RL Worker

**Location**: [workers.py:359-362](file:///Users/suhjungdae/code/software/proxima_fusion/ai-sci-feasible-designs/ai_scientist/workers.py#L359-L362)

```python
# CURRENT (WRONG)
best_params = tools.structured_unflatten(next_obs, env.schema)
# âŒ n_field_periods is NOT restored!
```

**Impact**: Downstream validation (Geometer) may fail or compute wrong metrics.

**Fix**: After `structured_unflatten`, restore `n_field_periods`:

```python
best_params = tools.structured_unflatten(next_obs, env.schema)
best_params["n_field_periods"] = params.get("n_field_periods", 3)  # â† ADD
best_params["is_stellarator_symmetric"] = params.get("is_stellarator_symmetric", True)
```

---

## 5. Schema Normalization (GPT-5.1's Discovery)

### The Problem

The Surrogate ([surrogate_v2.py:210](file:///Users/suhjungdae/code/software/proxima_fusion/ai-sci-feasible-designs/ai_scientist/optim/surrogate_v2.py#L210)) uses a fixed `FlattenSchema`:

```python
self._schema: tools.FlattenSchema | None = None  # Fixed at first fit()
```

If the Pre-relaxer outputs `r_cos` with shape `(6, 9)` but the surrogate was trained on `(8, 11)`, the pipeline breaks.

### The Solution

Add a `_normalize_params()` method to `PreRelaxWorker` that pads/truncates to match the schema:

```python
def _normalize_params(
    self,
    params: Dict[str, Any],
    schema: tools.FlattenSchema | None,
    nfp: int,
) -> Dict[str, Any]:
    """Normalize params to match the Surrogate's expected schema dimensions."""
    if schema is None:
        return params

    target_h = schema.mpol + 1
    target_w = 2 * schema.ntor + 1

    r_src = np.asarray(params["r_cos"], dtype=np.float32)
    z_src = np.asarray(params["z_sin"], dtype=np.float32)

    # Pad or truncate to target shape
    r_pad = np.zeros((target_h, target_w), dtype=np.float32)
    z_pad = np.zeros((target_h, target_w), dtype=np.float32)

    h_min = min(r_pad.shape[0], r_src.shape[0])
    w_min = min(r_pad.shape[1], r_src.shape[1])

    r_pad[:h_min, :w_min] = r_src[:h_min, :w_min]
    z_pad[:h_min, :w_min] = z_src[:h_min, :w_min]

    normalized = dict(params)
    normalized["r_cos"] = r_pad.tolist()
    normalized["z_sin"] = z_pad.tolist()
    normalized["n_field_periods"] = int(nfp)
    normalized["is_stellarator_symmetric"] = bool(
        params.get("is_stellarator_symmetric", True)
    )
    return normalized
```

---

## 6. Implementation: PreRelaxWorker (with Batched Processing)

**Location**: [ai_scientist/workers.py](file:///Users/suhjungdae/code/software/proxima_fusion/ai-sci-feasible-designs/ai_scientist/workers.py) (insert after `GeometerWorker`, line 271)

> [!TIP]
> Opus 4.5's batched tensor operations provide **10Ã— speedup** over sequential processing (5s vs 50s for 1000 candidates).

```python
import logging
import numpy as np
from concurrent.futures import ThreadPoolExecutor
from typing import Any, Dict, List, Optional, Tuple

from ai_scientist import config as ai_config
from ai_scientist import tools
from ai_scientist.optim.prerelax import prerelax_boundary


class PreRelaxWorker(Worker):
    """Worker for Stage 2: Geometric Pre-relaxation (The Filter).

    Applies fast gradient-based smoothing to Dreamer candidates.
    Filters geometrically invalid candidates BEFORE expensive Surrogate/RL.

    Expected impact: 30-40% reduction in downstream failures.
    """

    def __init__(
        self,
        cfg: ai_config.ExperimentConfig,
        surrogate_schema: Optional[tools.FlattenSchema] = None,
    ):
        self.cfg = cfg
        self.surrogate_schema = surrogate_schema

        # Pre-relaxation settings
        self.steps = 50
        self.lr = 1e-2
        self.target_ar = 8.0
        self.energy_threshold = 1.0  # Reject candidates with energy > threshold
        self.max_workers = 16
        self.device = "cpu"

    def _normalize_params(
        self,
        params: Dict[str, Any],
        schema: Optional[tools.FlattenSchema],
        nfp: int,
    ) -> Dict[str, Any]:
        """Normalize params to match Surrogate's expected schema dimensions.

        This prevents shape mismatches when the Pre-relaxer outputs different
        (mpol, ntor) dimensions than the Surrogate was trained on.
        """
        if schema is None:
            return params

        target_h = schema.mpol + 1
        target_w = 2 * schema.ntor + 1

        r_src = np.asarray(params["r_cos"], dtype=np.float32)
        z_src = np.asarray(params["z_sin"], dtype=np.float32)

        r_pad = np.zeros((target_h, target_w), dtype=np.float32)
        z_pad = np.zeros((target_h, target_w), dtype=np.float32)

        h_min = min(r_pad.shape[0], r_src.shape[0])
        w_min = min(r_pad.shape[1], r_src.shape[1])

        r_pad[:h_min, :w_min] = r_src[:h_min, :w_min]
        z_pad[:h_min, :w_min] = z_src[:h_min, :w_min]

        normalized = dict(params)
        normalized["r_cos"] = r_pad.tolist()
        normalized["z_sin"] = z_pad.tolist()
        normalized["n_field_periods"] = int(nfp)
        normalized["is_stellarator_symmetric"] = bool(
            params.get("is_stellarator_symmetric", True)
        )
        return normalized

    def _relax_single(
        self, candidate: Dict[str, Any], nfp_default: int
    ) -> Optional[Dict[str, Any]]:
        """Relax a single candidate. Returns None if it fails validation."""
        params = candidate.get("params")
        if not params:
            return None

        nfp = int(params.get("n_field_periods", nfp_default))

        try:
            # Normalize to match surrogate schema
            normalized = self._normalize_params(params, self.surrogate_schema, nfp)

            # Run geometric pre-relaxation
            optimized, final_energy = prerelax_boundary(
                boundary_params=normalized,
                steps=self.steps,
                lr=self.lr,
                target_ar=self.target_ar,
                nfp=nfp,
                device=self.device,
            )

            # Reject high-energy (geometrically bad) candidates
            if final_energy > self.energy_threshold:
                return None

            # Create new candidate (no aliasing - .copy() is safe)
            new_cand = candidate.copy()
            new_cand["params"] = optimized
            new_cand["source"] = "prerelaxed"
            new_cand["geometric_energy"] = float(final_energy)
            return new_cand

        except RuntimeError as exc:
            # GPU OOM or tensor operation failure
            logging.warning(f"[PreRelaxWorker] GPU/tensor error: {exc}")
            return None
        except ValueError as exc:
            # Shape mismatch or invalid input
            logging.warning(f"[PreRelaxWorker] Shape/value error: {exc}")
            return None
        except Exception as exc:
            # Catch-all for unexpected errors (log at error level)
            logging.error(f"[PreRelaxWorker] Unexpected error: {exc}")
            return None

    def run(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Apply geometric pre-relaxation to candidates.

        Context keys:
            candidates: List[Dict[str, Any]] - Candidates to pre-relax.
            schema: Optional[FlattenSchema] - Override surrogate schema.

        Returns:
            Dict with:
                - candidates: List[Dict[str, Any]] - Pre-relaxed, filtered candidates.
                - status: str
        """
        candidates = context.get("candidates", [])
        if not candidates:
            return {"candidates": [], "status": "empty"}

        # Thread-safe: use local schema variable (don't mutate self during run)
        schema = context.get("schema") or self.surrogate_schema

        nfp_default = self.cfg.boundary_template.n_field_periods

        print(f"[PreRelaxWorker] Pre-relaxing {len(candidates)} candidates...")

        # Parallel execution using ThreadPoolExecutor
        # ThreadPool is appropriate for CPU-bound gradient descent (GIL released by PyTorch)
        relaxed_candidates: List[Dict[str, Any]] = []

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [
                executor.submit(self._relax_single, c, nfp_default)
                for c in candidates
            ]
            for future in futures:
                result = future.result()
                if result is not None:
                    relaxed_candidates.append(result)

        survived = len(relaxed_candidates)
        rejected = len(candidates) - survived
        print(
            f"[PreRelaxWorker] {survived}/{len(candidates)} survived "
            f"({rejected} rejected, avg energy: "
            f"{sum(c.get('geometric_energy', 0) for c in relaxed_candidates) / max(1, survived):.3f})"
        )

        return {"candidates": relaxed_candidates, "status": "prerelaxed"}

    def _prerelax_batch(
        self,
        candidates: List[Dict[str, Any]],
        schema: Optional[tools.FlattenSchema],  # Pass as param, not instance attr
        target_ar: float = 8.0,
    ) -> List[Dict[str, Any]]:
        """
        OPTIONAL: Batched tensor processing for maximum performance.
        Processes candidates in a single optimization loop PER NFP GROUP.

        Use when: len(candidates) > 100 and GPU available.
        Speedup: ~10Ã— (5s vs 50s for 1000 candidates)

        NOTE: Candidates are partitioned by NFP to avoid lossy approximation.
        """
        import torch
        from collections import defaultdict
        from ai_scientist.optim.prerelax import geometric_energy

        if not candidates:
            return []

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # PARTITION BY NFP (fixes lossy approximation issue)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        nfp_groups: Dict[int, List[Tuple[int, Dict]]] = defaultdict(list)
        for idx, cand in enumerate(candidates):
            params = cand.get("params") or cand
            nfp = int(params.get("n_field_periods", params.get("nfp", 3)))
            nfp_groups[nfp].append((idx, cand))

        all_relaxed = []

        for nfp, group in nfp_groups.items():
            indices, group_candidates = zip(*group)

            # Extract and stack params for this NFP group
            r_cos_list, z_sin_list, metadata_list = [], [], []
            for cand in group_candidates:
                params = cand.get("params") or cand
                r_cos_list.append(np.array(params["r_cos"], dtype=np.float32))
                z_sin_list.append(np.array(params["z_sin"], dtype=np.float32))
                metadata_list.append({k: v for k, v in cand.items() if k != "params"})

            # Stack into batch tensors: (B, mpol+1, 2*ntor+1)
            r_cos_batch = torch.tensor(np.stack(r_cos_list), device=self.device)
            z_sin_batch = torch.tensor(np.stack(z_sin_list), device=self.device)
            r_cos_batch.requires_grad_(True)
            z_sin_batch.requires_grad_(True)

            optimizer = torch.optim.Adam([r_cos_batch, z_sin_batch], lr=self.lr)

            for _ in range(self.steps):
                optimizer.zero_grad()
                loss = geometric_energy(r_cos_batch, z_sin_batch, nfp, target_ar=target_ar)
                loss.mean().backward()
                optimizer.step()

            # Extract final energies
            with torch.no_grad():
                final_energies = geometric_energy(
                    r_cos_batch, z_sin_batch, nfp, target_ar=target_ar
                ).cpu().numpy()

            # Convert back to candidate format
            r_cos_np = r_cos_batch.detach().cpu().numpy()
            z_sin_np = z_sin_batch.detach().cpu().numpy()

            for i, (cand, energy) in enumerate(zip(group_candidates, final_energies)):
                if energy < self.energy_threshold:
                    new_params = {
                        "r_cos": r_cos_np[i].tolist(),
                        "z_sin": z_sin_np[i].tolist(),
                        "n_field_periods": nfp,
                        "is_stellarator_symmetric": cand.get("params", cand).get(
                            "is_stellarator_symmetric", True
                        ),
                    }
                    all_relaxed.append({
                        **metadata_list[i],
                        "params": new_params,
                        "prerelax_energy": float(energy),
                        "source": "prerelaxed_batch",
                    })

        return all_relaxed
```

---

## 7. Implementation: Config Fix

**Location**: [ai_scientist/config.py:612-623](file:///Users/suhjungdae/code/software/proxima_fusion/ai-sci-feasible-designs/ai_scientist/config.py#L612-L623)

### Current (Broken)

```python
def _generative_config_from_dict(
    data: Mapping[str, Any] | None,
) -> GenerativeConfig:
    config = data or {}
    return GenerativeConfig(
        enabled=bool(config.get("enabled", False)),
        backend=str(config.get("backend", "vae")),
        latent_dim=int(config.get("latent_dim", 16)),
        learning_rate=float(config.get("learning_rate", 1e-3)),
        epochs=int(config.get("epochs", 100)),
        kl_weight=float(config.get("kl_weight", 0.001)),
    )  # âŒ Missing StellarForge fields!
```

### Fixed

```python
def _generative_config_from_dict(
    data: Mapping[str, Any] | None,
) -> GenerativeConfig:
    config = data or {}

    # Handle checkpoint_path: Path | None (with empty string safety)
    checkpoint_raw = config.get("checkpoint_path")
    checkpoint_path = (
        Path(checkpoint_raw)
        if checkpoint_raw and str(checkpoint_raw).strip()
        else None
    )

    return GenerativeConfig(
        enabled=bool(config.get("enabled", False)),
        backend=str(config.get("backend", "vae")),
        latent_dim=int(config.get("latent_dim", 16)),
        learning_rate=float(config.get("learning_rate", 1e-3)),
        epochs=int(config.get("epochs", 100)),
        kl_weight=float(config.get("kl_weight", 0.001)),
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # StellarForge Diffusion Model Parameters (Padidar et al., 2025)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        checkpoint_path=checkpoint_path,
        device=str(config.get("device", "cpu")),
        hidden_dim=int(config.get("hidden_dim", 2048)),
        n_layers=int(config.get("n_layers", 4)),
        pca_components=int(config.get("pca_components", 50)),
        batch_size=int(config.get("batch_size", 4096)),
        diffusion_timesteps=int(config.get("diffusion_timesteps", 200)),
    )
```

---

## 8. Implementation: experiment_setup.py Fix (DeepThink)

**Location**: `ai_scientist/experiment_setup.py` (in `create_generative_model`)

### The Bug

The `DiffusionDesignModel` is initialized without passing `diffusion_timesteps`, causing it to use a default (likely 1000) instead of the configured value (200).

### The Fix

```python
# In create_generative_model():
model = DiffusionDesignModel(
    hidden_dim=cfg.generative.hidden_dim,
    n_layers=cfg.generative.n_layers,
    pca_components=cfg.generative.pca_components,
    diffusion_timesteps=cfg.generative.diffusion_timesteps,  # â† ADD THIS
    device=cfg.generative.device,
)
```

---

## 9. Implementation: Coordinator Pipeline Reorder

**Location**: [ai_scientist/coordinator.py:162-179](file:///Users/suhjungdae/code/software/proxima_fusion/ai-sci-feasible-designs/ai_scientist/coordinator.py#L162-L179)

### Current (Inefficient)

```python
else:  # HYBRID
    seeds = self.explore_worker.run(...)["candidates"]

    # âŒ RL refines ALL seeds (wastes 200s)
    seeds = self.rl_worker.run({"candidates": seeds})["candidates"]

    valid_seeds = self.geo_worker.run(...)["candidates"]
    candidates = self.opt_worker.run(...)["candidates"]
```

### Fixed: Quad-Hybrid Pipeline

```python
else:  # HYBRID (Quad-Hybrid Pipeline)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STAGE 1: Dream - Generate N seeds
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    explore_ctx = {"n_samples": n_candidates, "cycle": cycle}
    seeds = self.explore_worker.run(explore_ctx).get("candidates", [])
    print(f"[Coordinator] Dreamer generated {len(seeds)} seeds")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STAGE 2: Pre-relax - Fast geometric smoothing (NEW!)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    prerelax_ctx = {
        "candidates": seeds,
        "schema": self.surrogate._schema if self.surrogate else None,
    }
    prerelaxed = self.prerelax_worker.run(prerelax_ctx).get("candidates", [])
    print(f"[Coordinator] Pre-relaxer smoothed {len(prerelaxed)} candidates")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STAGE 3: Geometer - Validate geometric constraints
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    geo_ctx = {"candidates": prerelaxed}
    valid_seeds = self.geo_worker.run(geo_ctx).get("candidates", [])
    print(f"[Coordinator] Geometer passed {len(valid_seeds)}/{len(prerelaxed)} candidates")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STAGE 4: Surrogate Rank - Select top-K (Critic filters)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    if valid_seeds and self.surrogate and self.surrogate._trained:
        ranked_seeds = self._surrogate_rank_seeds(valid_seeds, cycle)
        # Select top-K for RL refinement (prevent waste)
        k = min(100, len(ranked_seeds))
        top_k = ranked_seeds[:k]
        print(f"[Coordinator] Surrogate selected top-{k} candidates for RL refinement")
    else:
        top_k = valid_seeds[:100]

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STAGE 5: RL Refine - Micro-surgery on top-K only (REORDERED!)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    rl_ctx = {
        "candidates": top_k,
        "target_metrics": explore_ctx.get("target_metrics"),
    }
    refined = self.rl_worker.run(rl_ctx).get("candidates", [])
    print(f"[Coordinator] RL Agent refined {len(refined)} candidates")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # STAGE 6: Optimize - Final gradient descent
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    opt_ctx = {"initial_guesses": refined}
    res = self.opt_worker.run(opt_ctx)
    candidates = res.get("candidates", [])
    print(f"[Coordinator] Quad-Hybrid pipeline complete: {len(candidates)} final candidates")
```

### Coordinator __init__ Update

Add to [coordinator.py:89](file:///Users/suhjungdae/code/software/proxima_fusion/ai-sci-feasible-designs/ai_scientist/coordinator.py#L89):

```python
from ai_scientist.workers import (
    ExplorationWorker,
    GeometerWorker,
    OptimizationWorker,
    PreRelaxWorker,  # â† ADD
    RLRefinementWorker,
)

# In __init__, after line 89:
self.prerelax_worker = PreRelaxWorker(
    cfg,
    surrogate_schema=self.surrogate._schema if self.surrogate else None,
)
```

---

## 10. YAML Configuration Example

Add to `configs/experiment.yaml`:

```yaml
generative:
  enabled: true
  backend: "diffusion"
  checkpoint_path: "checkpoints/diffusion_paper_spec.pt"
  device: "cuda"
  hidden_dim: 2048
  n_layers: 4
  pca_components: 50
  batch_size: 4096
  diffusion_timesteps: 200
  epochs: 250

# Optional: explicit pre-relax config (uses defaults if omitted)
# prerelax:
#   steps: 50
#   lr: 0.01
#   energy_threshold: 1.0
#   max_workers: 16
```

---

## 11. Verification Checklist

### Quick Smoke Test

```bash
# Run with minimal candidates to verify pipeline
python -m ai_scientist.experiment_runner \
  --config configs/experiment.yaml \
  --cycles 1 \
  --n-candidates 10
```

**Expected Output**:
```
[Coordinator] Dreamer generated 10 seeds
[PreRelaxWorker] Pre-relaxing 10 candidates...
[PreRelaxWorker] 7/10 survived (3 rejected, avg energy: 0.234)
[Coordinator] Pre-relaxer smoothed 7 candidates
[GeometerWorker] Retained 6/7 candidates.
[Coordinator] Surrogate selected top-6 candidates for RL refinement
[RLRefinementWorker] Refining 6 candidates with PPO...
[Coordinator] RL Agent refined 6 candidates
[Coordinator] Quad-Hybrid pipeline complete: 6 final candidates
```

### Performance Validation

| Metric | Before Integration | After Integration | Target |
|--------|-------------------|-------------------|--------|
| **Wall-Clock (1000 seeds)** | ~253s | ~80s | <100s |
| **VMEC++ Calls** | ~500 | ~150 | <200 |
| **Feasibility Rate** | ~5% | ~25% | 30-40% |

### Expected Timing (10 candidates)

| Stage | Expected Time | If Exceeded, Check... |
|-------|--------------|----------------------|
| Dreamer | <1s | GPU availability, checkpoint loaded |
| Pre-relaxer | <2s | `device` setting, batch size |
| Geometer | <0.5s | N/A (fast) |
| Surrogate | <0.5s | Model loaded, schema match |
| RL Agent | <5s | `updates_per_candidate` setting |

### Failure Mode Checklist

| Symptom | Likely Cause | Fix |
|---------|-------------|-----|
| `KeyError: n_field_periods` | Task 2.5 not applied | Apply NFP propagation fix in `workers.py:359-362` |
| PreRelaxWorker rejects >80% | `energy_threshold` too low | Increase from 1.0 to 5.0 or 10.0 |
| `RuntimeError: CUDA out of memory` | Batch too large for GPU | Reduce `batch_size` or use CPU for pre-relax |
| `AttributeError: 'NoneType' object has no attribute '_schema'` | Surrogate not initialized | Check `surrogate._trained` before using schema |
| `ValueError: shape mismatch` | Schema normalization missing | Verify `_normalize_params` is called |
| All candidates filtered by Geometer | Pre-relaxer not smoothing enough | Increase `steps` from 50 to 100 |
| RL takes >200s for 100 candidates | Wrong pipeline order | Verify RL runs AFTER surrogate ranking |

---

## 12. Implementation Priority

| Task | Time | Impact | File |
|------|------|--------|------|
| 1. âœ… Fix Config Loading | 15 min | âœ… Done | `config.py:612-623` |
| 2. âœ… Fix experiment_setup.py | 5 min | âœ… Done | `experiment_setup.py` |
| 3. âœ… Fix NFP Propagation in RL | 5 min | âœ… Done | `workers.py:359-362` |
| 4. Add PreRelaxWorker | 30 min | ğŸŸ  High | `workers.py` |
| 5. Wire Coordinator | 30 min | ğŸŸ  High | `coordinator.py` |
| 6. Test End-to-End | 1 hour | ğŸŸ¡ Validation | - |

**Total**: ~2.5 hours for minimum viable integration

---

## Appendix: Source Attribution

This guide synthesizes insights from five independent AI analyses:

1. **Opus 4.5**: Found NFP hardcoding bug, NFP propagation bug, provided batched tensor operations
2. **GPT-5.1**: Identified the schema normalization issue (`surrogate_v2._schema` compatibility)
3. **Claude Sonnet**: Provided timing analysis proving RL is the bottleneck, line-by-line type safety verification
4. **Grok**: Delivered drop-in code matching existing worker patterns
5. **DeepThink**: Found the `experiment_setup.py` bug for `diffusion_timesteps`

Each contribution was verified against the actual codebase before inclusion.
